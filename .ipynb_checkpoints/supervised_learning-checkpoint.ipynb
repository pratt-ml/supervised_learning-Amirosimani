{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397f11e8-d2b8-47cb-81b4-8900cd2c4321",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7fda15-fe39-4698-af4e-820312a1d76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e16bc85-394f-4066-b547-57945c352c5c",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720fdc6c-b684-42fd-83e4-883a22b99e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data from the url into a pandas dataframe\n",
    "col_name = ['A1', 'A2', 'A3','A4','A5','A6','A7','A8','A9','A10','A11','A12','A13','A14','A15','A16']\n",
    "data_path = \"http://archive.ics.uci.edu/ml/machine-learning-databases/credit-screening/crx.data\"\n",
    "\n",
    "df = pd.read_csv(data_path, sep=',', names=col_name)\n",
    "\n",
    "# pay attention how I've taken the file path and col names out of pd.read_csv().\n",
    "# Overall, this is a good practice to assign long arguments to variables and then pass those variables to your function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17581476-5f95-41f2-bc67-5700fe8888f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check datatypes to compare with the info in crx.names\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589662ac-e02c-4871-be5d-416079c36853",
   "metadata": {},
   "source": [
    "A2 and A14 should've had dtype of either `float` or `integer`, but they are objects -> something is going on here! maybe missing data - this is a good guess since the data description on `crx.names` says A2 and A14 have missing data.\n",
    "```    A1:  12\n",
    "    A2:  12\n",
    "    A4:   6\n",
    "    A5:   6\n",
    "    A6:   9\n",
    "    A7:   9\n",
    "    A14: 13\n",
    "    \n",
    "    \n",
    "let's convert one of them to numeric type and see what rows are causing problem\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8950f868-0956-4cab-9c95-3d339ea68729",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_numeric(df['A2'], errors=\"raise\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fd2276-2c9b-458a-90db-889c44128954",
   "metadata": {},
   "source": [
    "REMEBER: last line of error log is usually the most important line you have to look at initially!\n",
    "\n",
    "From the error `ValueError: Unable to parse string \"?\" at position 83` I can see that row 83 with the value of `?` is causing issue.\n",
    "\n",
    "refering to `imputation` strategies, I have multiple options. since the data dictoinary (crx.name) tells me the number of missing values are not that much (at most ~2% in column A14), i'll drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775982c5-ff3c-4498-b8a7-e1582258529c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert selected columns to numeric dtype\n",
    "df[['A2', 'A14']] = df[['A2', 'A14']].apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066bcd88-b036-47bf-a51a-a94d5389f050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check number of missing values to compare with the data dictionary\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be1190b-7ee0-4fe3-bb57-0769ccfcc601",
   "metadata": {},
   "source": [
    "I can see that A2 and A14 now have the same number of missing values as the data dictionary says. However, A1, A4, 5, 6, 7 also should have missing values, but it doesn't show here. My guess is that because they have data type of object (string), I need to find what is used to denote missing values. Let's check..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71de6942-f752-4b6e-9c45-8aa5c2ce0177",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['A1', 'A4', 'A5', 'A6', 'A7']:\n",
    "    print(col, \": \", df[col].unique(), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db67d49-085e-456b-bbae-34f0d8c82ddf",
   "metadata": {},
   "source": [
    "I see that all those columns have '?' in their values. so now I need to convert `?` to `NaN`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72024038-f172-4262-93bb-f1dd48c20281",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace('?',np.NaN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97482bb-23b1-433f-870b-c5f327375707",
   "metadata": {},
   "source": [
    "Now let's count NaNs one more time..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ce2df8-c9d7-4de0-84ba-3b446f43c942",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d47ce4-255a-40cb-810e-b7843ec150fe",
   "metadata": {},
   "source": [
    "Perfect! now I'm getting the same numbers as the data dictionary suggests.  I can simply  drop those rows.\n",
    "However, I want to show you how you can add imputation to your **pipeline**. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18d60c8-ec40-4573-a7d5-5a2b3ee81e3c",
   "metadata": {},
   "source": [
    "### Check solution for assignment 1 for More EDAV!!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5656e28c-5810-4ccd-ba4e-11b2836a9f11",
   "metadata": {},
   "source": [
    "# 2- Linear Leaner\n",
    "\n",
    "\n",
    "important: always use **pipelines**.\n",
    "\n",
    "I am using logistic regression. you can use other linear classifiers like SVM as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa4bc84-5a3a-4b3c-b652-fdfd42102cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperating features and lables\n",
    "X = df.loc[:, df.columns != 'A16']\n",
    "y = df['A16']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241500fa-c5b0-4459-b734-66308bdcc8d7",
   "metadata": {},
   "source": [
    "`ColumnTransformer` is a great method to apply different preprocessing and feature extraction pipelines to different subsets of features . \n",
    "\n",
    "This is particularly handy for the case of datasets that contain heterogeneous data types, since we may want to scale the numeric features and one-hot encode the categorical ones.\n",
    "\n",
    "In this example, the numeric data is standard-scaled after mean-imputation, while the categorical data is one-hot encoded after imputing missing values with a new category ('missing').\n",
    "\n",
    "I'm using `Chelsea`'s solution with some modification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58d84bd-da4e-410c-868a-c3a09af9770a",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = X.select_dtypes(exclude='O').columns\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[(\"imputer\", SimpleImputer(strategy=\"median\")), (\"scaler\", StandardScaler())]\n",
    ")\n",
    "\n",
    "categorical_features = X.select_dtypes(include='O').columns\n",
    "categorical_transformer = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8bd20a-0754-4611-b40f-ffd14e6e0203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's add a linear classifier to preprocessing pipeline to create a full prediction pipeline.\n",
    "clf_linear = Pipeline(\n",
    "    steps=[(\"preprocessor\", preprocessor), \n",
    "           (\"classifier\", LogisticRegression(random_state=seed))]\n",
    ")\n",
    "\n",
    "clf_linear.fit(X_train, y_train)\n",
    "print(\"model score: %.3f\" % clf_linear.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a067b8-83e6-4ee7-b11f-98e898337c93",
   "metadata": {},
   "source": [
    "### Evaluating the linear model on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bc783e-401a-450c-8515-d26029e95d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_linear = clf_linear.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_linear))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81347172-0db4-455d-b3cc-25b560366147",
   "metadata": {},
   "source": [
    "### Cross-validation (optional)\n",
    "Below is an example of `5 fold cross-validation` for the linear learner, in case you want to generate cross-validated estimates. You can apply the same logic/code for other models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c31bce5-caf4-4061-8e3b-c28887b68094",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_score = np.mean(cross_val_score(clf_linear, X_test, y_test, cv=5))\n",
    "print(\"model score: %.3f\" % cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befeb0ed-6e4c-492b-8985-c113741d176e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_linear_cv = cross_val_predict(clf_linear, X_test, y_test, cv=5)\n",
    "\n",
    "print(classification_report(y_test, y_pred_linear_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449858e7-c7ea-4c6b-a21c-bbcbfbdfc0e5",
   "metadata": {},
   "source": [
    "# 3- Non-Linear Learner\n",
    "\n",
    "\n",
    "important: always use **pipelines**.\n",
    "\n",
    "I am using kNN. you can use other non-linear classifiers like decision trees as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14036a44-d803-4b91-8117-9982601222ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_non_linear = Pipeline(\n",
    "    steps=[(\"preprocessor\", preprocessor), \n",
    "           (\"classifier\", KNeighborsClassifier(n_neighbors=5))]\n",
    ")\n",
    "\n",
    "clf_non_linear.fit(X_train, y_train)\n",
    "print(\"model score: %.3f\" % clf_non_linear.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc65ce35-3a79-4bf9-82bf-6657a12ad54d",
   "metadata": {},
   "source": [
    "### Evaluating the non-linear model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5ca63e-c50b-4cb3-8138-1a56eeae8c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_nonlinear = clf_non_linear.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_nonlinear))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8b6ff5-607d-4b37-b25e-0b3b9f70e42b",
   "metadata": {},
   "source": [
    "You can see that I'm getting a better F1 score for both classes using a non-linear model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12ab84c-f1c3-48d0-8745-dbe02817694d",
   "metadata": {},
   "source": [
    "### look how clean and easy it is to change a step when you use pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd085b22-fa41-4972-a7a7-d9d4b58e80bb",
   "metadata": {},
   "source": [
    "# 4- Ensemble model\n",
    "In this section, we will use one of the discussed ensemble methods to create a new model based on step 2 and 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e01ff5-47d6-4c6a-b560-d752bb32ffe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = VotingClassifier(\n",
    "    estimators=[('lr', LogisticRegression(random_state=seed)),\n",
    "                ('knn', KNeighborsClassifier(n_neighbors=5))],\n",
    "    voting='hard')\n",
    "\n",
    "clf_ensemble = Pipeline(\n",
    "    steps=[(\"preprocessor\", preprocessor), \n",
    "           (\"classifier\", ensemble)]\n",
    "       )\n",
    "\n",
    "clf_ensemble.fit(X_train, y_train)\n",
    "print(\"model score: %.3f\" % clf_ensemble.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b226fcf-9402-4522-977b-e3eb210b6117",
   "metadata": {},
   "source": [
    "### Evaluating the ensemble model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5ef846-315c-4e80-ae0d-659a2cd05e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ensemble = clf_ensemble.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_ensemble))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8178746-ad61-4f91-8a4c-98433c5f69ac",
   "metadata": {},
   "source": [
    "I can see improvement in precision for `-` class, while worse result for other metrics. This is ok! We shouldn't expect a more complex model to be naturally better! also I haven't run any hyperparameter optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c298b0d8-cb9f-45ad-9ebf-9bc0a05fcb80",
   "metadata": {},
   "source": [
    "# 5- Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc72ebab-951d-480d-a850-cdd2a0705699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# declaring the function\n",
    "def credit_approval(row, model=clf_ensemble):\n",
    "   \"\"\"\n",
    "   Main function to take a sample data and use a trained model to predict if sample's application will get approved or not\n",
    "\n",
    "   row: sample data\n",
    "   model: ensemble model you have already trained\n",
    "   \"\"\"\n",
    "   \n",
    "   result = model.predict(row)\n",
    "   \n",
    "   return result\n",
    "\n",
    "\n",
    "# i passed the clf_ensemble as the default value for the model argument of the function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51733327-49f6-4eb6-ba97-0334c84ed47f",
   "metadata": {},
   "source": [
    "Now I can use my `test set` to get prediction. the following does it for the first row in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e74f475-1d72-427d-9aec-1678bd79c026",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Predicted value:\", credit_approval(X_test.iloc[[0]]))\n",
    "print(\"Real value:\", y_test.iloc[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
